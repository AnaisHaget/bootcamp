{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 17: Review of exercise 2\n",
    "\n",
    "(c) 2019 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "Exercises 2.3 and 2.4  were inspired by [Libeskind-Hadas and Bush, *Computing for Biologists*, Cambridge University Press, 2014](https://www.cs.hmc.edu/CFB).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This lesson was generated from a Jupyter notebook.  You can download the notebook [here](l17_exercise_2.ipynb).*\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import bootcamp_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Parsing a FASTA file\n",
    "\n",
    "There are packages, like [Biopython](http://biopython.org/) and [scikit-bio](http://scikit-bio.org) for processing files you encounter in bioinformatics.  In this problem, though, we will work on our file I/O skills.  \n",
    "\n",
    "**a)** Use command line tools to investigate the [FASTA file](https://en.wikipedia.org/wiki/FASTA_format) located at `~git/bootcamp/data/salmonella_spi1_region.fna`. This file contains a portion of the _Salmonella genome_ (described in [Exercise 2.3](#Exercise-2.3%3A-Pathogenicity-islands)).\n",
    "\n",
    "You will notice that the first line begins with a `>`, signifying that the line contains information about the sequence.  The remainder of the lines are the sequence itself.\n",
    "\n",
    "**b)** The format of the _Salmonella_ SPI1 region FASTA file is a common format for such files (though oftentimes FASTA files contain multiple sequences). Use the file I/O skills you have learned to write a function to read in a sequence from a FASTA file containing a single sequence (but possibly having the first line in the file beginning with `>`). Your function should take as input the name of the FASTA file and return two strings. First, it should return the descriptor string (which starts with `>`). Second, it should return a string with no gaps containing the sequence.\n",
    "\n",
    "Test your function on the _Salmonella_ sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: solution\n",
    "\n",
    "**a)** A quick look using `less` indicates that this is a valid FASTA file.  I did a quick check to see how many sequences there are by searching for the `>` symbol using `grep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">gi|821161554|gb|CP011428.1| Salmonella enterica subsp. enterica strain YU39, complete genome, subsequence 3000000 to 3200000\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" data/salmonella_spi1_region.fna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Lambda_NEB\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" data/lambdaDNA.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in both there is a single record. So, when we read it in, we just need to skip the first line and read on until we get the full record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We will read in the files line by line, saving the first line as the descriptor, and then building the sequence as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(filename):\n",
    "    \"\"\"Read a sequence in from a FASTA file containing a single sequence.\n",
    "    \n",
    "    We assume that the first line of the file is the descriptor and all\n",
    "    subsequent lines are sequence.    \n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        # Read in descriptor\n",
    "        descriptor = f.readline().rstrip()\n",
    "\n",
    "        # Read in sequence, stripping the whitespace from each line\n",
    "        seq = ''\n",
    "        line = f.readline().rstrip()\n",
    "        while line != '':\n",
    "            seq += line\n",
    "            line = f.readline().rstrip()\n",
    "            \n",
    "    return descriptor, seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, when writing this function, we should be taking a test-driven development approach, but here we are focusing on our file I/O and string handling skills.\n",
    "\n",
    "Let's take the function for a drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAACCTTAGTAACTGGACTGCTGGGATTTTTCAGCCTGGATACGCTGGTAGATCTCTTCACGATGGACAGAAACTTCTTTCGGGGCGTTCACGCCAATACGCACCTGGTTGCCCTTCACCCCTAAAACTGTCACGGTGACCTCATCGCCAATCATGAGGGTCTCACCAACTCGACGAGTCAGAATCAGCATTCTTTGCTCCTTGAAAGATTAAAAGAGTCGGGTCTCTCTGTATCCCGGCATTATCCATCATATAACGCCAAAAAGTAAGCGATGACAAACACCTTAGGTGTAAGCAGTCATGGCATTACATTCTGTTAAACCTAAGTTTAGCCGATATACAAAACTTCAACCTGACTTTATCGTTGTCGATAGCGTTGACGTAAACGCCGCAGCACGGGCTGCGGCGCCAACGAACGCTTATAATTATTGCAATTTTGCGCTGACCCAGCCTTGTACACTGGCTAACGCTGCAGGCAGAGCTGCCGCATCCGTACCAC'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor, seq = read_fasta('data/salmonella_spi1_region.fna')\n",
    "\n",
    "# Take a look at the first 500 bases to make sure we got it right.\n",
    "seq[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "And for the λ-DNA...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGGCGGCGACCTCGCGGGTTTTCGCTATTTATGAAAATTTTCCGGTTTAAGGCGTTTCCGTTCTTCTTCGTCATAACTTAATGTTTTTATTTAAAATACCCTCTGAAAAGAAAGGAAACGACAGGTGCTGAAAGCGAGGCTTTTTGGCCTCTGTCGTTTCCTTTCTCTGTTTTTGTCCGTGGAATGAACAATGGAAGTCAACAAAAAGCAGCTGGCTGACATTTTCGGTGCGAGTATCCGTACCATTCAGAACTGGCAGGAACAGGGAATGCCCGTTCTGCGAGGCGGTGGCAAGGGTAATGAGGTGCTTTATGACTCTGCCGCCGTCATAAAATGGTATGCCGAAAGGGATGCTGAAATTGAGAACGAAAAGCTGCGCCGGGAGGTTGAAGAACTGCGGCAGGCCAGCGAGGCAGATCTCCAGCCAGGAACTATTGAGTACGAACGCCATCGACTTACGCGTGCGCAGGCCGACGCACAGGAACTGAAGAATGCCAGAG'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor_lambda, seq_lambda = read_fasta('data/lambdaDNA.fasta')\n",
    "\n",
    "# Take a look at the first 500 bases to make sure we got it right.\n",
    "seq_lambda[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Restriction cut sites\n",
    "\n",
    "**[Restriction enzymes](https://en.wikipedia.org/wiki/Restriction_enzyme)** cut DNA at specific locations called **restriction sites**. The sequence at a restriction site is called a **recognition sequence**. Here are the recognition sequences of some commonly used restriction enzymes.\n",
    "\n",
    "|Restriction enzyme | Recognition sequence|\n",
    "|:----|:----|\n",
    "|[HindIII](https://en.wikipedia.org/wiki/HindIII) | `AAGCTT` |\n",
    "|[EcoRI](https://en.wikipedia.org/wiki/EcoRI)| `GAATTC` |\n",
    "|KpnI| `GGTACC` |\n",
    "\n",
    "\n",
    "**a)** Download the FASTA file ([New England Biosystems](https://www.neb.com/products/n3011-lambda-dna#Product%20Information)) from  containing the genome of λ-phage, a bacteriophage that infect _E. coli_, [here](https://www.neb.com/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/lambdafsa.txt). Use the function you wrote in Exercise 2.1 to extract the sequence.\n",
    "\n",
    "**b)** Write a function with call signature\n",
    "\n",
    "```python\n",
    "restriction_sites(seq, recoq_seq)\n",
    "```\n",
    "\n",
    "that takes as arguments a sequence and the recognition sequence of a restriction enzyme sites and returns the indices of the first base or each of the restriction sites in the sequence. Use this function to find the indices of the restriction sites of λ-DNA for HindIII, EcoRI, and KpnI. Compare your results to those reported on the [New England Biosystems datasheet](https://www.neb.com/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/lambda_sites.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: solution\n",
    "\n",
    "**a)** I have downloaded the FASTA file to `data/lambdaDNA.fasta`. Let's load it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, seq = read_fasta('data/lambdaDNA.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to make sure we got the whole sequence, which should be about 48.5 kbp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48502"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "**b)** Our goal is to find all locations of the substring given by the recognition sequence in the genome. This is most easily accomplished using the `re` module that uses **[regular expressions](https://en.wikipedia.org/wiki/Regular_expression)**. We [covered this in bootcamp 2015](http://justinbois.github.io/bootcamp/2015/lessons/l16_regular_expressions.html), but have since cut it from the course. Specifically, we use `re.finditer()` to automatically find all occurrences of the recognition sequence in the sequence, and then use the `start()` method to get the first index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_sites_with_re(seq, recog_seq):\n",
    "    \"\"\"Find the indices of all restriction sites in a sequence.\"\"\"\n",
    "    sites = []\n",
    "    for site in re.finditer(recog_seq, seq):\n",
    "        sites.append(site.start())\n",
    "        \n",
    "    return sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our restriction sites against the know sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HindIII: [23129, 25156, 27478, 36894, 37458, 37583, 44140]\n",
      "EcoRI:   [21225, 26103, 31746, 39167, 44971]\n",
      "KpnI:    [17052, 18555]\n"
     ]
    }
   ],
   "source": [
    "print('HindIII:', restriction_sites_with_re(seq, 'AAGCTT'))\n",
    "print('EcoRI:  ', restriction_sites_with_re(seq, 'GAATTC'))\n",
    "print('KpnI:   ', restriction_sites_with_re(seq, 'GGTACC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly, these match exactly the listed values, except each index reported by our function is one less than the listed values because we are indexing starting at zero. The one example that is different from the data sheet is that the data sheet does not contain the cut site at index 37583. This could be because NEB made a mistake either in the sequencing or in determining their cut cits, or because they validated the cut sites experimentally, and for some reason there is some strange structure around that cut site that precludes cutting.\n",
    "\n",
    "I will now write a function do to the same calculation without using regular expressions. We will simply make a pass through the sequence and store the indices where we match the recognition sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_sites(seq, recog_seq):\n",
    "    \"\"\"Find the indices of all restriction sites in a sequence.\"\"\"\n",
    "    # Initialize list of restriction sites\n",
    "    sites = []\n",
    "\n",
    "    # Check every substring for a match\n",
    "    for i in range(len(seq) - len(recog_seq)):\n",
    "        if seq[i:i+len(recog_seq)] == recog_seq:\n",
    "            sites.append(i)\n",
    "        \n",
    "    return sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HindIII: [23129, 25156, 27478, 36894, 37458, 37583, 44140]\n",
      "EcoRI:   [21225, 26103, 31746, 39167, 44971]\n",
      "KpnI:    [17052, 18555]\n"
     ]
    }
   ],
   "source": [
    "print('HindIII:', restriction_sites(seq, 'AAGCTT'))\n",
    "print('EcoRI:  ', restriction_sites(seq, 'GAATTC'))\n",
    "print('KpnI:   ', restriction_sites(seq, 'GGTACC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, we can compare the speeds of the two functions using the magic function `%timeit`. This function performs a calculation many times and computes a mean execution time. It can be used to check speed of your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6 ms ± 76.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "166 µs ± 3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit restriction_sites(seq, 'AAGCTT')\n",
    "%timeit restriction_sites_with_re(seq, 'AAGCTT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression-based method is nearly 100 times faster! This is often the case; hand-coding something in pure Python can be slow compared to using packages that use pre-compiled code like `re`. However, as [Donald Knuth](https://en.wikipedia.org/wiki/Donald_Knuth) said, \"The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; **premature optimization is the root of all evil (or at least most of it) in programming.**\" Get your code working, even if it is slow, and optimize only if you have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Pathogenicity islands\n",
    "For this and the next problem, we will work with real data from the *Salmonella enterica* genome.  The section of the genome we will work with is in the file `~git/bootcamp/data/salmonella_spi1_region.fna`.  I cut it out of the [full genome](http://www.ncbi.nlm.nih.gov/nucleotide/821161554).  It contains *Salmonella* pathogenicity island I (SPI1), which contains genes for surface receptors for host-pathogen interactions.\n",
    "\n",
    "Pathogenicity islands are often marked by different GC content than the rest of the genome.  We will try to locate the pathogenicity island(s) in our section of the *Salmonella* genome by computing GC content.\n",
    "\n",
    "**a)** Use principles of TDD to write a function that divides a sequence into blocks and computes the GC content for each block, returning a tuple. The function signature should look like\n",
    "\n",
    "    gc_blocks(seq, block_size)\n",
    "    \n",
    "To be clear, if `seq = 'ATGACTACGT'` and `block_size = 4`, the blocks to be considered are\n",
    "\n",
    "    ATGA\n",
    "    CTAC\n",
    "    \n",
    "and the function should return `(0.25, 0.5)`. Note that the blocks are non-overlapping and that we don't bother with the fact that end of the sequence that does not fit completely in a block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Write a function that takes as input a sequence, block size, and a threshold GC content, and returns the original sequence where every base in a block with GC content above threshold is capitalized and every base below the threshold is lowercase. You would call the function like this:\n",
    "\n",
    "    mapped_seq = gc_map(seq, block_size, gc_thresh)\n",
    "\n",
    "For example, \n",
    "\n",
    "    gc_map('ATGACTACGT', 4, 0.4)\n",
    "\n",
    "returns `'atgaCTAC'`. Note that bases not included in GC blocks are not included in the output sequence. Again, use principles of TDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Use the `gc_map()` function to generate a GC content map for the *Salmonella* sequence with `block_size = 1000` and `gc_thresh = 0.45`. Where do you think the pathogenicity island is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Write the GC-mapped sequence (with upper and lower characters) to a new FASTA file. Use the same description line (which began with a `>` in the original FASTA file), and have line breaks every 60 characters in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Solution\n",
    "\n",
    "**a)** First let's write our tests. In writing the tests, I am making the design decision that I will count the characters `G`, `g`, `C`, and `c` as contributing to GC content, and that I will not check to make sure the sequence is valid. I also make the design decision that an empty sequence has zero GC content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gc_content():\n",
    "    assert gc_content('') == 0.0\n",
    "    assert gc_content('G') == 1.0\n",
    "    assert gc_content('g') == 1.0\n",
    "    assert gc_content('C') == 1.0\n",
    "    assert gc_content('c') == 1.0\n",
    "    assert gc_content('gcgcgc') == 1.0\n",
    "    assert gc_content('aaatatata') == 0.0\n",
    "    assert np.isclose(gc_content('ggatcggcga'), 0.7)\n",
    "    assert np.isclose(gc_content('attgggggcaatta'), 3/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is fairly simple. We loop through the sequence with a stride equal to the block size, computing the GC content for each subsequence of that length. We start with a function to compute GC content for a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_content(seq):\n",
    "    \"\"\"GC content of a given sequence\"\"\"\n",
    "    if seq == '':\n",
    "        return 0.0\n",
    "    \n",
    "    seq = seq.upper()\n",
    "    return (seq.count('G') + seq.count('C')) / len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gc_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage! Next, we write the looping function, starting with its tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gc_blocks():\n",
    "    assert gc_blocks('', 10) == tuple()\n",
    "    assert gc_blocks('gcgcgcgcg', 10) == tuple()\n",
    "    assert gc_blocks('gcgcgcg', 4) == (1.0,)\n",
    "    assert gc_blocks('gcgcgcgc', 4) == (1.0, 1.0)\n",
    "    assert gc_blocks('gcgcgcgcat', 4) == (1.0, 1.0)\n",
    "\n",
    "    test_tuple = gc_blocks('gcgagcgcat', 4)\n",
    "    assert np.isclose(test_tuple[0], 0.75) and test_tuple[1] == 1.0\n",
    "    \n",
    "    assert gc_blocks('gcgtagagc', 1) == (1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0)\n",
    "    assert gc_blocks('gcgtagagc', 2) == (1.0, 0.5, 0.5, 0.5)\n",
    "    assert np.isclose(gc_blocks('gcgtagagc', 3), (1.0, 1/3, 2/3)).sum() == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_blocks(seq, block_size):\n",
    "    \"\"\"\n",
    "    Divide sequence into non-overlapping blocks\n",
    "    and compute GC content of each block.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    for i in range(0, len(seq) - (len(seq) % block_size), block_size):\n",
    "        blocks.append(gc_content(seq[i:i+block_size]))\n",
    "    return tuple(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the tests...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gc_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Let's take this function for a spin, looking at 1000-base blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.516,\n",
       " 0.543,\n",
       " 0.551,\n",
       " 0.584,\n",
       " 0.604,\n",
       " 0.594,\n",
       " 0.55,\n",
       " 0.578,\n",
       " 0.554,\n",
       " 0.572,\n",
       " 0.58,\n",
       " 0.582,\n",
       " 0.59,\n",
       " 0.574,\n",
       " 0.585,\n",
       " 0.562,\n",
       " 0.584,\n",
       " 0.589,\n",
       " 0.535,\n",
       " 0.55,\n",
       " 0.589,\n",
       " 0.515,\n",
       " 0.424,\n",
       " 0.308,\n",
       " 0.406,\n",
       " 0.364,\n",
       " 0.351,\n",
       " 0.397,\n",
       " 0.447,\n",
       " 0.434,\n",
       " 0.474,\n",
       " 0.502,\n",
       " 0.512,\n",
       " 0.429,\n",
       " 0.403,\n",
       " 0.456,\n",
       " 0.41,\n",
       " 0.435,\n",
       " 0.451,\n",
       " 0.522,\n",
       " 0.5,\n",
       " 0.475,\n",
       " 0.496,\n",
       " 0.461,\n",
       " 0.498,\n",
       " 0.492,\n",
       " 0.46,\n",
       " 0.375)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc_blocks(seq, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a tuple of GC content, which is hard to look at on screen, but this is useful for plotting GC content over the course of a sequence. We will learn how to plot later in the bootcamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We just use our already-written `gc_content()` function to decide how to modify the string of the sequence. First, the tests. We make the design decision that we will truncate the sequence if the 3'-most end is shorter than the block length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gc_map():\n",
    "    assert gc_map('', 10, 0.5) == ''\n",
    "    assert gc_map('ATATATATA', 4, 0.5) == 'atatatat'\n",
    "    assert gc_map('GCGCGCGCG', 4, 0.5) == 'GCGCGCGC'\n",
    "    assert gc_map('GATCGATCC', 4, 0.5) == 'GATCGATC'\n",
    "    assert gc_map('GATCGATCC', 4, 0.51) == 'gatcgatc'\n",
    "    assert gc_map('GATCGATCC', 3, 0.5) == 'gatCGATCC'\n",
    "    assert gc_map('GATCGATCC', 3, 0.75) == 'gatcgatcc'\n",
    "    assert gc_map('GATCGATCC', 3, 0.25) == 'GATCGATCC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_map(seq, block_size, gc_thresh):\n",
    "    \"\"\"Give back seq with lowercase letters where GC content is low.\"\"\" \n",
    "    out_seq = ''\n",
    "\n",
    "    # Determine GC content of each block and change string accordingly\n",
    "    for i in range(0, len(seq) - (len(seq) % block_size), block_size):\n",
    "        if gc_content(seq[i:i+block_size]) < gc_thresh:\n",
    "            out_seq += seq[i:i+block_size].lower()\n",
    "        else:\n",
    "            out_seq += seq[i:i+block_size].upper()\n",
    "\n",
    "    return out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gc_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage! We can now use these functions to analyze sequences of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Let's do it for *Salmonella*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sal_gcmap = gc_map(seq, 1000, 0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save on display space, we will not display the sequence here.  Scrolling through the GC map file generated in the next part, the pathogenicity island appears to occur about a quarter of the way into this subsequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** To write the file out, we use the fact that we conveniently kept the description text when we parsed the *Salmonella* FASTA file in the first place.  We then just write the `sal_gcmap` string in blocks of 60.  We have to make sure to get the last few bases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the result\n",
    "with open('salmonella_spi1_region_gc_map.fna', 'w') as f:\n",
    "    # Write description text\n",
    "    f.write(descriptor + '\\n')\n",
    "\n",
    "    # Write sequence in blocks of 60\n",
    "    i = 0\n",
    "    while i < len(sal_gcmap) - 59:\n",
    "        f.write(sal_gcmap[i:i+60] + '\\n')\n",
    "        i += 60\n",
    "    \n",
    "    # Write last line\n",
    "    f.write(sal_gcmap[i:] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a quick look to see it worked out ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">gi|821161554|gb|CP011428.1| Salmonella enterica subsp. enterica strain YU39, complete genome, subsequence 3000000 to 3200000\n",
      "GGGCGGCGACCTCGCGGGTTTTCGCTATTTATGAAAATTTTCCGGTTTAAGGCGTTTCCG\n",
      "TTCTTCTTCGTCATAACTTAATGTTTTTATTTAAAATACCCTCTGAAAAGAAAGGAAACG\n",
      "ACAGGTGCTGAAAGCGAGGCTTTTTGGCCTCTGTCGTTTCCTTTCTCTGTTTTTGTCCGT\n",
      "GGAATGAACAATGGAAGTCAACAAAAAGCAGCTGGCTGACATTTTCGGTGCGAGTATCCG\n",
      "TACCATTCAGAACTGGCAGGAACAGGGAATGCCCGTTCTGCGAGGCGGTGGCAAGGGTAA\n",
      "TGAGGTGCTTTATGACTCTGCCGCCGTCATAAAATGGTATGCCGAAAGGGATGCTGAAAT\n",
      "TGAGAACGAAAAGCTGCGCCGGGAGGTTGAAGAACTGCGGCAGGCCAGCGAGGCAGATCT\n",
      "CCAGCCAGGAACTATTGAGTACGAACGCCATCGACTTACGCGTGCGCAGGCCGACGCACA\n",
      "GGAACTGAAGAATGCCAGAGACTCCGCTGAAGTGGTGGAAACCGCATTCTGTACTTTCGT\n",
      "...\n",
      "ccttccatgtgatacgagggcgcgtagtttgcattatcgtttttatcgtttcaatctggt\n",
      "ctgacctccttgtgttttgttgatgatttatgtcaaatattaggaatgttttcacttaat\n",
      "agtattggttgcgtaacaaagtgcggtcctgctggcattctggagggaaatacaaccgac\n",
      "agatgtatgtaaggccaacgtgctcaaatcttcatacagaaagatttgaagtaatatttt\n",
      "aaccgctagatgaagagcaagcgcatggagcgacaaaatgaataaagaacaatctgctga\n",
      "tgatccctccgtggatctgattcgtgtaaaaaatatgcttaatagcaccatttctatgag\n",
      "ttaccctgatgttgtaattgcatgtatagaacataaggtgtctctggaagcattcagagc\n",
      "aattgaggcagcgttggtgaagcacgataataatatgaaggattattccctggtggttga\n",
      "ctgatcaccataactgctaatcattcaaactatttagtctgtgacagagccaacacgcag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head salmonella_spi1_region_gc_map.fna\n",
    "print('...')\n",
    "!tail salmonella_spi1_region_gc_map.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4: ORF detection\n",
    "\n",
    "For this problem, again use principles of TDD to help you write your functions.\n",
    "\n",
    "**a)** Write a function, `longest_orf()`, that takes a DNA sequence as input and finds the longest open reading frame (ORF) in the sequence (we will not consider reverse complements).  A sequence fragment constitutes an ORF if the following are all true.\n",
    "\n",
    "1. It begins with `ATG`.\n",
    "2. It ends with any of `TGA`, `TAG`, or `TAA`.\n",
    "3. The total number of bases is a multiple of 3.\n",
    "\n",
    "Note that the sequence `ATG` may appear in the middle of an ORF.  So, for example,\n",
    "\n",
    "    GGATGATGATGTAAAAC\n",
    "\n",
    "has two ORFs, `ATGATGATGTAA` and `ATGATGTAA`.  You would return the first one, since it is longer of these two.\n",
    "\n",
    "*Hint: The statement for this problem is a bit ambiguous as it is written.  What other specification might you need for this function?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use your function to find the longest ORF from the section of the *Salmonella* genome we are investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Write a function that converts a DNA sequence into a protein sequence. You can of course use the `bootcamp_utils` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Translate the longest ORF you generated in part (b) into a protein sequence and perform a [BLAST search](http://blast.ncbi.nlm.nih.gov/). Search for the protein sequence (a blastp query). What gene is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** [*Bonus challenge*] Modify your function to return the `n` longest ORFs. Compute the five longest ORFs for the *Salmonella* genome section we are working with. Perform BLAST searches on them. What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: solution\n",
    "\n",
    "**a)** Something was missing in the specification.  Namely, what do we do if there are two ORFs of the same longest length?  Do we return the first one, second one, or both?  I am arbitrarily choosing to return the one with the 3$'$-most starting index.  \n",
    "\n",
    "Looking ahead to part (e), I will first write a function to return all ORFs that are not entirely included in a longer ORF.  For ease of storage and comparison, I will simply store the ORFS as the index of the start of the ORF and the noninclusive index of the last.\n",
    "\n",
    "Let's now discuss the algorithm we'll use. There are more efficient ways of finding ORFs, but I will choose a very clear way.  We'll first find all start codons. For each start codon, we will find the first in-register stop codon. If there is an in-register stop codon, we store this start-stop pair. At the end, we sort them, longest to shortest.\n",
    "\n",
    "So, we really have three functions we'll use.  `find_all_starts(seq)` will return the indices of all start codons in a sequence.  `find_next_in_register_stop(seq)` will scan a sequence that starts with `ATG` and return the exclusive final index of the next in register stop codon. In other words, and ORF starting at index `start` is given by\n",
    "\n",
    "    seq[start:start+find_next_in_register_stop(seq[start:])]\n",
    "\n",
    "If there is no such codon, `find_next_in_register_stop()` returns `-1`. Finally, `all_orfs(seq)` returns the sorted tuple of 2-tuples containing the start/stop pairs of the ORFs.\n",
    "\n",
    "I will use TDD principles for designing these functions, writing the test cases first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_find_all_starts():\n",
    "    assert find_all_starts('') == tuple()\n",
    "    assert find_all_starts('GGAGACGACGCAAAAC'.lower()) == tuple()\n",
    "    assert find_all_starts('AAAAAAATGAAATGAGGGGGGTATG'.lower()) == (6, 11, 22)\n",
    "    assert find_all_starts('GGATGATGATGTAAAAC'.lower()) == (2, 5, 8)\n",
    "    assert find_all_starts('GGATGCATGATGTAGAAC'.lower()) == (2, 6, 9)\n",
    "    assert find_all_starts('GGGATGATGATGGGATGGTGAGTAGGGTAAG'.lower()) == \\\n",
    "                                                               (3, 6, 9, 14)\n",
    "    assert find_all_starts('GGGatgatgatgGGatgGtgaGtagGGACtaaG'.lower()) == \\\n",
    "                                                               (3, 6, 9, 14)    \n",
    "    \n",
    "    \n",
    "def test_find_first_in_register_stop():\n",
    "    assert find_first_in_register_stop('') == -1\n",
    "    assert find_first_in_register_stop('GTAATAGTGA'.lower()) == -1\n",
    "    assert find_first_in_register_stop('AAAAAAAAAAAAAAATAAGGGTAA'.lower()) == 18\n",
    "    assert find_first_in_register_stop('AAAAAACACCGCGTGTACTGA'.lower()) == 21\n",
    "    \n",
    "    \n",
    "def test_all_orfs():\n",
    "    assert all_orfs('') == tuple()\n",
    "    assert all_orfs('GGAGACGACGCAAAAC') == tuple()\n",
    "    assert all_orfs('AAAAAAATGAAATGAGGGGGGTATG') == ((6, 15),)\n",
    "    assert all_orfs('GGATGATGATGTAAAAC') == ((2, 14),)\n",
    "    assert all_orfs('GGATGCATGATGTAGAAC') == ((6, 15),)\n",
    "    assert all_orfs('GGGATGATGATGGGATGGTGAGTAGGGTAAG') == ((3, 21),)\n",
    "    assert all_orfs('GGGatgatgatgGGatgGtgaGtagGGACtaaG') == ((14, 32), (3, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the `find_all_starts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find all start codons in sequence\"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll fail the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-97d4ba12adeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_find_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-5c76a7a3caff>\u001b[0m in \u001b[0;36mtest_find_all_starts\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_find_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGAGACGACGCAAAAC'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAATGAAATGAGGGGGGTATG'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGATGATGATGTAAAAC'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write the function. I'll use regular expressions first, but will also code up the function without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find the starting index of all start codons in a lowercase seq\"\"\"\n",
    "    # Compile regex for start codons\n",
    "    regex_start = re.compile('atg')\n",
    "        \n",
    "    # Find the indices of all start codons\n",
    "    starts = []\n",
    "    for match in regex_start.finditer(seq):\n",
    "        starts.append(match.start())\n",
    "        \n",
    "    return tuple(starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see if it passes the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  We passed!  However, since we did not learn regular expressions this year, I will write a function that finds all start codons that does not use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find the starting index of all start codons in a lowercase seq\"\"\"\n",
    "    # Initialize array of indices of start codons\n",
    "    starts = []\n",
    "    \n",
    "    # Find index of first start codon (remember, find() returns -1 if not found)\n",
    "    i = seq.find('atg')\n",
    "    \n",
    "    # Keep looking for subsequence incrementing starting point of search\n",
    "    while i >= 0:\n",
    "        starts.append(i)\n",
    "        i = seq.find('atg', i + 1)\n",
    "        \n",
    "    return tuple(starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test this new `find_all_starts()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It passed! Yay! Note how useful TDD is here. Whenever we try new ways of doing things, we can use the tests to make sure we didn't break anything.\n",
    "\n",
    "Now, let's move on to the next function, which finds the first in-register stop codon. Again, we fail, and then write the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-99ed189bf75f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_find_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-5c76a7a3caff>\u001b[0m in \u001b[0;36mtest_find_first_in_register_stop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_find_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GTAATAGTGA'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAAAAAAAAAATAAGGGTAA'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    return None\n",
    "\n",
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, beautiful failure. Now, we'll write the function and test it. Again, I'll demonstrate the power of the `re` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    \"\"\"\n",
    "    Find first stop codon on lowercase seq that starts at an index\n",
    "    that is divisible by three\n",
    "    \"\"\"\n",
    "    # Compile regexes for stop codons\n",
    "    regex_stop = re.compile('(taa|tag|tga)')\n",
    "    \n",
    "    # Stop codon iterator\n",
    "    stop_iterator = regex_stop.finditer(seq)\n",
    "\n",
    "    # Find next stop codon that is in register\n",
    "    for stop in stop_iterator:\n",
    "        if stop.end() % 3 == 0:\n",
    "            return stop.end()\n",
    "        \n",
    "    # Return -1 if we failed to find a stop codon\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It passes. Now, I'll write it without regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    \"\"\"\n",
    "    Find first stop codon on seq that starts at an index\n",
    "    that is divisible by three\n",
    "    \"\"\"\n",
    "\n",
    "    seq = seq.lower()\n",
    "\n",
    "    # Scan sequence for stop codon\n",
    "    i = 0\n",
    "    while i < len(seq) - 2 and seq[i:i+3] not in ('taa', 'tag', 'tga'):\n",
    "        i += 3\n",
    "\n",
    "    # If before end, found codon, return end of codon\n",
    "    if i < len(seq) - 2:\n",
    "        return i + 3\n",
    "    else: # Failed to find stop codon\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage!  Finally, we apply TDD to write `all_orfs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_orfs(seq):\n",
    "    \"\"\"Return all ORFs of a sequence.\"\"\"\n",
    "    # Make sure sequence is all lower case\n",
    "    seq = seq.lower()\n",
    "        \n",
    "    # Find the indices of all start codons\n",
    "    start_inds = find_all_starts(seq)\n",
    "        \n",
    "    # Keep track of stops\n",
    "    stop_inds = []\n",
    "        \n",
    "    # Initialze ORFs.  Each entry in list is [ORF length, ORF start, ORF stop]\n",
    "    orfs = []\n",
    "        \n",
    "    # For each start codon, find the next stop codon in register\n",
    "    for start in start_inds:\n",
    "        relative_stop = find_first_in_register_stop(seq[start:])\n",
    "        \n",
    "        if relative_stop != -1:\n",
    "            # Index of stop codon\n",
    "            stop = start + relative_stop\n",
    "            \n",
    "            # If already had stop, a longer ORF contains this one\n",
    "            if stop not in stop_inds:\n",
    "                orfs.append((relative_stop, start, stop))\n",
    "                stop_inds.append(stop)\n",
    "                        \n",
    "    # Get sorted list of ORF length\n",
    "    orfs = sorted(orfs, reverse=True)\n",
    "    \n",
    "    # Remove lengths\n",
    "    for i, orf in enumerate(orfs):\n",
    "        orfs[i] = (orf[1], orf[2])\n",
    "    \n",
    "    return tuple(orfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the tests...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_orfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage!  We have succeed in generating an ordered list of the ORFs.  Now, let's get what the problem specified, the longest ORF.  Of course, we start with writing tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_longest_orf():\n",
    "    assert longest_orf('') == ''\n",
    "    assert longest_orf('GGAGACGACGCAAAAC') == ''\n",
    "    assert longest_orf('AAAAAAATGAAATGAGGGGGGTATG') == 'ATGAAATGA'\n",
    "    assert longest_orf('GGATGATGATGTAAAAC') == 'ATGATGATGTAA'\n",
    "    assert longest_orf('GGATGCATGATGTAGAAC') == 'ATGATGTAG'\n",
    "    assert longest_orf('GGGATGATGATGGGATGGTGAGTAGGGTAAG') == 'ATGATGATGGGATGGTGA'\n",
    "    assert (longest_orf('GGGatgatgatgGGatgGtgaGtagGGACtaaG')\n",
    "                == 'atgGtgaGtagGGACtaa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fail them...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5408c7075a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_longest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-ea5298a7be36>\u001b[0m in \u001b[0;36mtest_longest_orf\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_longest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGAGACGACGCAAAAC'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAATGAAATGAGGGGGGTATG'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ATGAAATGA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGATGATGATGTAAAAC'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ATGATGATGTAA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def longest_orf(seq):\n",
    "    return None\n",
    "\n",
    "test_longest_orf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write our function, and then test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_orf(seq):\n",
    "    \"\"\"Longest ORF of a sequence.\"\"\"\n",
    "    orfs = all_orfs(seq)\n",
    "    \n",
    "    if len(orfs) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return seq[orfs[0][0]:orfs[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_longest_orf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage! Success! We now have a reliable function for computing the longest ORF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We simply use our new function to find the longest ORF of the *Salmonella* sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATGGGTAAAGGAAGCAGTAAGGGGCATACCCCGCGCGAAGCGAAGGACAACCTGAAGTCCACGCAGTTGCTGAGTGTGATCGATGCCATCAGCGAAGGGCCGATTGAAGGTCCGGTGGATGGCTTAAAAAGCGTGCTGCTGAACAGTACGCCGGTGCTGGACACTGAGGGGAATACCAACATATCCGGTGTCACGGTGGTGTTCCGGGCTGGTGAGCAGGAGCAGACTCCGCCGGAGGGATTTGAATCCTCCGGCTCCGAGACGGTGCTGGGTACGGAAGTGAAATATGACACGCCGATCACCCGCACCATTACGTCTGCAAACATCGACCGTCTGCGCTTTACCTTCGGTGTACAGGCACTGGTGGAAACCACCTCAAAGGGTGACAGGAATCCGTCGGAAGTCCGCCTGCTGGTTCAGATACAACGTAACGGTGGCTGGGTGACGGAAAAAGACATCACCATTAAGGGCAAAACCACCTCGCAGTATCTGGCCTCGGTGGTGATGGGTAACCTGCCGCCGCGCCCGTTTAATATCCGGATGCGCAGGATGACGCCGGACAGCACCACAGACCAGCTGCAGAACAAAACGCTCTGGTCGTCATACACTGAAATCATCGATGTGAAACAGTGCTACCCGAACACGGCACTGGTCGGCGTGCAGGTGGACTCGGAGCAGTTCGGCAGCCAGCAGGTGAGCCGTAATTATCATCTGCGCGGGCGTATTCTGCAGGTGCCGTCGAACTATAACCCGCAGACGCGGCAATACAGCGGTATCTGGGACGGAACGTTTAAACCGGCATACAGCAACAACATGGCCTGGTGTCTGTGGGATATGCTGACCCATCCGCGCTACGGCATGGGGAAACGTCTTGGTGCGGCGGATGTGGATAAATGGGCGCTGTATGTCATCGGCCAGTACTGCGACCAGTCAGTGCCGGACGGCTTTGGCGGCACGGAGCCGCGCATCACCTGTAATGCGTACCTGACCACACAGCGTAAGGCGTGGGATGTGCTCAGCGATTTCTGCTCGGCGATGCGCTGTATGCCGGTATGGAACGGGCAGACGCTGACGTTCGTGCAGGACCGACCGTCGGATAAGACGTGGACCTATAACCGCAGTAATGTGGTGATGCCGGATGATGGCGCGCCGTTCCGCTACAGCTTCAGCGCCCTGAAGGACCGCCATAATGCCGTTGAGGTGAACTGGATTGACCCGAACAACGGCTGGGAGACGGCGACAGAGCTTGTTGAAGATACGCAGGCCATTGCCCGTTACGGTCGTAATGTTACGAAGATGGATGCCTTTGGCTGTACCAGCCGGGGGCAGGCACACCGCGCCGGGCTGTGGCTGATTAAAACAGAACTGCTGGAAACGCAGACCGTGGATTTCAGCGTCGGCGCAGAAGGGCTTCGCCATGTACCGGGCGATGTTATTGAAATCTGCGATGATGACTATGCCGGTATCAGCACCGGTGGTCGTGTGCTGGCGGTGAACAGCCAGACCCGGACGCTGACGCTCGACCGTGAAATCACGCTGCCATCCTCCGGTACCGCGCTGATAAGCCTGGTTGACGGAAGTGGCAATCCGGTCAGCGTGGAGGTTCAGTCCGTCACCGACGGCGTGAAGGTAAAAGTGAGCCGTGTTCCTGACGGTGTTGCTGAATACAGCGTATGGGAGCTGAAGCTGCCGACGCTGCGCCAGCGACTGTTCCGCTGCGTGAGTATCCGTGAGAACGACGACGGCACGTATGCCATCACCGCCGTGCAGCATGTGCCGGAAAAAGAGGCCATCGTGGATAACGGGGCGCACTTTGACGGCGAACAGAGTGGCACGGTGAATGGTGTCACGCCGCCAGCGGTGCAGCACCTGACCGCAGAAGTCACTGCAGACAGCGGGGAATATCAGGTGCTGGCGCGATGGGACACACCGAAGGTGGTGAAGGGCGTGAGTTTCCTGCTCCGTCTGACCGTAACAGCGGACGACGGCAGTGAGCGGCTGGTCAGCACGGCCCGGACGACGGAAACCACATACCGCTTCACGCAACTGGCGCTGGGGAACTACAGGCTGACAGTCCGGGCGGTAAATGCGTGGGGGCAGCAGGGCGATCCGGCGTCGGTATCGTTCCGGATTGCCGCACCGGCAGCACCGTCGAGGATTGAGCTGACGCCGGGCTATTTTCAGATAACCGCCACGCCGCATCTTGCCGTTTATGACCCGACGGTACAGTTTGAGTTCTGGTTCTCGGAAAAGCAGATTGCGGATATCAGACAGGTTGAAACCAGCACGCGTTATCTTGGTACGGCGCTGTACTGGATAGCCGCCAGTATCAATATCAAACCGGGCCATGATTATTACTTTTATATCCGCAGTGTGAACACCGTTGGCAAATCGGCATTCGTGGAGGCCGTCGGTCGGGCGAGCGATGATGCGGAAGGTTACCTGGATTTTTTCAAAGGCAAGATAACCGAATCCCATCTCGGCAAGGAGCTGCTGGAAAAAGTCGAGCTGACGGAGGATAACGCCAGCAGACTGGAGGAGTTTTCGAAAGAGTGGAAGGATGCCAGTGATAAGTGGAATGCCATGTGGGCTGTCAAAATTGAGCAGACCAAAGACGGCAAACATTATGTCGCGGGTATTGGCCTCAGCATGGAGGACACGGAGGAAGGCAAACTGAGCCAGTTTCTGGTTGCCGCCAATCGTATCGCATTTATTGACCCGGCAAACGGGAATGAAACGCCGATGTTTGTGGCGCAGGGCAACCAGATATTCATGAACGACGTGTTCCTGAAGCGCCTGACGGCCCCCACCATTACCAGCGGCGGCAATCCTCCGGCCTTTTCCCTGACACCGGACGGAAAGCTGACCGCTAAAAATGCGGATATCAGTGGCAGTGTGAATGCGAACTCCGGGACGCTCAGTAATGTGACGATAGCTGAAAACTGTACGATAAACGGTACGCTGAGGGCGGAAAAAATCGTCGGGGACATTGTAAAGGCGGCGAGCGCGGCTTTTCCGCGCCAGCGTGAAAGCAGTGTGGACTGGCCGTCAGGTACCCGTACTGTCACCGTGACCGATGACCATCCTTTTGATCGCCAGATAGTGGTGCTTCCGCTGACGTTTCGCGGAAGTAAGCGTACTGTCAGCGGCAGGACAACGTATTCGATGTGTTATCTGAAAGTACTGATGAACGGTGCGGTGATTTATGATGGCGCGGCGAACGAGGCGGTACAGGTGTTCTCCCGTATTGTTGACATGCCAGCGGGTCGGGGAAACGTGATCCTGACGTTCACGCTTACGTCCACACGGCATTCGGCAGATATTCCGCCGTATACGTTTGCCAGCGATGTGCAGGTTATGGTGATTAAGAAACAGGCGCTGGGCATCAGCGTGGTCTGA'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute it\n",
    "salmonella_orf = longest_orf(seq)\n",
    "\n",
    "# Look at it\n",
    "salmonella_orf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** We can use the `codons` dictionary in the `bootcamp_utils` package to do the translation.  With this in hand, we can write our `translate()` function.  We will scan the DNA sequence, generate a list of amino acids, and then join them into a protein sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(seq):\n",
    "    \"\"\"Translate a DNA sequence into protein\"\"\"\n",
    "    # Make sure sequence is upper case\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    # Find start codon\n",
    "    i = 0\n",
    "    while i < len(seq) + 2 and seq[i:i+3] != 'ATG':\n",
    "        i += 1\n",
    "\n",
    "    # Translate until the stop codon or end of string\n",
    "    prot = []\n",
    "    while i < len(seq) - 2 and seq[i:i+3] not in ('TAA', 'TGA', 'TAG'):\n",
    "        prot.append(bootcamp_utils.codons[seq[i:i+3]])\n",
    "        i += 3\n",
    "\n",
    "    return ''.join(prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** We can now translate the protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MGKGSSKGHTPREAKDNLKSTQLLSVIDAISEGPIEGPVDGLKSVLLNSTPVLDTEGNTNISGVTVVFRAGEQEQTPPEGFESSGSETVLGTEVKYDTPITRTITSANIDRLRFTFGVQALVETTSKGDRNPSEVRLLVQIQRNGGWVTEKDITIKGKTTSQYLASVVMGNLPPRPFNIRMRRMTPDSTTDQLQNKTLWSSYTEIIDVKQCYPNTALVGVQVDSEQFGSQQVSRNYHLRGRILQVPSNYNPQTRQYSGIWDGTFKPAYSNNMAWCLWDMLTHPRYGMGKRLGAADVDKWALYVIGQYCDQSVPDGFGGTEPRITCNAYLTTQRKAWDVLSDFCSAMRCMPVWNGQTLTFVQDRPSDKTWTYNRSNVVMPDDGAPFRYSFSALKDRHNAVEVNWIDPNNGWETATELVEDTQAIARYGRNVTKMDAFGCTSRGQAHRAGLWLIKTELLETQTVDFSVGAEGLRHVPGDVIEICDDDYAGISTGGRVLAVNSQTRTLTLDREITLPSSGTALISLVDGSGNPVSVEVQSVTDGVKVKVSRVPDGVAEYSVWELKLPTLRQRLFRCVSIRENDDGTYAITAVQHVPEKEAIVDNGAHFDGEQSGTVNGVTPPAVQHLTAEVTADSGEYQVLARWDTPKVVKGVSFLLRLTVTADDGSERLVSTARTTETTYRFTQLALGNYRLTVRAVNAWGQQGDPASVSFRIAAPAAPSRIELTPGYFQITATPHLAVYDPTVQFEFWFSEKQIADIRQVETSTRYLGTALYWIAASINIKPGHDYYFYIRSVNTVGKSAFVEAVGRASDDAEGYLDFFKGKITESHLGKELLEKVELTEDNASRLEEFSKEWKDASDKWNAMWAVKIEQTKDGKHYVAGIGLSMEDTEEGKLSQFLVAANRIAFIDPANGNETPMFVAQGNQIFMNDVFLKRLTAPTITSGGNPPAFSLTPDGKLTAKNADISGSVNANSGTLSNVTIAENCTINGTLRAEKIVGDIVKAASAAFPRQRESSVDWPSGTRTVTVTDDHPFDRQIVVLPLTFRGSKRTVSGRTTYSMCYLKVLMNGAVIYDGAANEAVQVFSRIVDMPAGRGNVILTFTLTSTRHSADIPPYTFASDVQVMVIKKQALGISVV'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(salmonella_orf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a BLAST search on this protein indicates that it is a histidine kinase involved in signaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** We already are computing all of the ORFs. We an therefore just add a kwarg to our `longest_orf()` function to get the `n` longest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_orf(seq, n=1):\n",
    "    \"\"\"Longest ORF of a sequence.\"\"\"\n",
    "    orfs = all_orfs(seq)\n",
    "    \n",
    "    if len(orfs) == 0:\n",
    "        return ''\n",
    "    elif n == 1 or len(orfs) == 1:\n",
    "        return seq[orfs[0][0]:orfs[0][1]]\n",
    "    else:\n",
    "        return_list = []\n",
    "        for i in range(min(n, len(orfs))):\n",
    "            return_list.append(seq[orfs[i][0]:orfs[i][1]])\n",
    "        return tuple(return_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll compute the ORFs, translate them, and make a FASTA file to submit for a BLAST search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute ORFs\n",
    "orfs = longest_orf(seq, n=5)\n",
    "\n",
    "# Translate them\n",
    "prots = []\n",
    "for orf in orfs:\n",
    "    prots.append(translate(orf))\n",
    "    \n",
    "# Make a FASTA file\n",
    "with open('sal_seqs.faa', 'w') as f:\n",
    "    for i, prot in enumerate(prots):\n",
    "        f.write('> {0:d}\\n'.format(i))\n",
    "        f.write(prot + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at it to see what I did with the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "MGKGSSKGHTPREAKDNLKSTQLLSVIDAISEGPIEGPVDGLKSVLLNSTPVLDTEGNTNISGVTVVFRAGEQEQTPPEGFESSGSETVLGTEVKYDTPITRTITSANIDRLRFTFGVQALVETTSKGDRNPSEVRLLVQIQRNGGWVTEKDITIKGKTTSQYLASVVMGNLPPRPFNIRMRRMTPDSTTDQLQNKTLWSSYTEIIDVKQCYPNTALVGVQVDSEQFGSQQVSRNYHLRGRILQVPSNYNPQTRQYSGIWDGTFKPAYSNNMAWCLWDMLTHPRYGMGKRLGAADVDKWALYVIGQYCDQSVPDGFGGTEPRITCNAYLTTQRKAWDVLSDFCSAMRCMPVWNGQTLTFVQDRPSDKTWTYNRSNVVMPDDGAPFRYSFSALKDRHNAVEVNWIDPNNGWETATELVEDTQAIARYGRNVTKMDAFGCTSRGQAHRAGLWLIKTELLETQTVDFSVGAEGLRHVPGDVIEICDDDYAGISTGGRVLAVNSQTRTLTLDREITLPSSGTALISLVDGSGNPVSVEVQSVTDGVKVKVSRVPDGVAEYSVWELKLPTLRQRLFRCVSIRENDDGTYAITAVQHVPEKEAIVDNGAHFDGEQSGTVNGVTPPAVQHLTAEVTADSGEYQVLARWDTPKVVKGVSFLLRLTVTADDGSERLVSTARTTETTYRFTQLALGNYRLTVRAVNAWGQQGDPASVSFRIAAPAAPSRIELTPGYFQITATPHLAVYDPTVQFEFWFSEKQIADIRQVETSTRYLGTALYWIAASINIKPGHDYYFYIRSVNTVGKSAFVEAVGRASDDAEGYLDFFKGKITESHLGKELLEKVELTEDNASRLEEFSKEWKDASDKWNAMWAVKIEQTKDGKHYVAGIGLSMEDTEEGKLSQFLVAANRIAFIDPANGNETPMFVAQGNQIFMNDVFLKRLTAPTITSGGNPPAFSLTPDGKLTAKNADISGSVNANSGTLSNVTIAENCTINGTLRAEKIVGDIVKAASAAFPRQRESSVDWPSGTRTVTVTDDHPFDRQIVVLPLTFRGSKRTVSGRTTYSMCYLKVLMNGAVIYDGAANEAVQVFSRIVDMPAGRGNVILTFTLTSTRHSADIPPYTFASDVQVMVIKKQALGISVV\n",
      "> 1\n",
      "MAEPVGDLVVDLSLDAARFDEQMARVRRHFSGTESDAKKTAAVVEQSLSRQALAAQKAGISVGQYKAAMRMLPAQFTDVATQLAGGQSPWLILLQQGGQVKDSFGGMIPMFRGLAGAITLPMVGATSLAVATGALAYAWYQGNSTLSDFNKTLVLSGNQAGLTADRMLVLSRAGQAAGLTFNQTSESLSALVKAGVSGEAQIASISQSVARFSSASGVEVDKVAEAFGKLTTDPTSGLTAMARQFHNVSAEQIAYVAQLQRSGDEAGALQAANEAATKGFDDQTRRLKENMGTLETWADRTARAFKSMWDAVLDIGRPDTAQEMLIKAEAAYKKADDIWNLRKDDYFVNDEARARYWDDREKARLALEAARKKAEQQTQQDKNAQQQSDTEASRLKYTEEAQKAYERLQTPLEKYTARQEELNKALKDGKILQADYNTLMAAAKKDYEATLKKPKQSSVKVSAGDRQEDSAHAALLTLQAELRTLEKHAGANEKISQQRRDLWKAESQFAVLEEAAQRRQLSAQEKSLLAHKDETLEYKRQLAALGDKVTYQERLNALAQQADKFAQQQRAKRAAIDAKSRGLTDRQAEREATEQRLKEQYGDNPLALNNVMSEQKKTWAAEDQLRGNWMAGLKSGWSEWEESATDSMSQVKSAATQTFDGIAQNMAAMLTGSEQNWRSFTRSVLSMMTEILLKQAMVGIVGSIGSAIGGAVGGGASASGGTAIQAAAAKFHFATGGFTGTGGKYEPAGIVHRGEFVFTKEATSRIGVGNLYRLMRGYATGGYVGTPGSMADSRSQASGTFEQNNHVVINNDGTNGQIGPAALKAVYDMARKGARDEIQTQMRDGGLFSGGGR\n",
      "> 2\n",
      "MNAMGSDYIREVNVVKSARVGYSKMLLGVYAYFIEHKQRNTLIWLPTDGDAENFMKTHVEPTIRDIPSLLALAPWYGKKHRDNTLTMKRFTNGRGFWCLGGKAAKNYREKSVDVAGYDELAAFDDDIEQEGSPTFLGDKRIEGSVWPKSIRGSTPKVRGTCQIERAASESPHFMRFHVACPHCGEEQYLKFGDKETPFGLKWTPDDPSSVFYLCEHNACVIRQQELDFTDARYICEKTGIWTRDGILWFSSSGEEIEPPDSVTFHIWTAYSPFTTWVQIVKDWMKTKGDTGKRKTFVNTTLGETWEAKIGERPDAEVMAERKEHYSAPVPDRVAYLTAGIDSQLDRYEMRVWGWGPGEESWLIDRQIIMGRHDDEQTLLRVDEAINKTYTRRNGAEMSISRICWDTGGIDPTIVYERSKKHGLFRVIPIKGASVYGKPVASMPRKRNKNGVYLTEIGTDTAKEQIYNRFTLTPEGDEPLPGAVHFPNNPDIFDLTEAQQLTAEEQVEKWVDGRKKILWDSKKRRNEALDCFVYALAALRISISRWQLDLSALLASLQEEDGAATNKKTLADYARALSGEDE\n",
      "> 3\n",
      "MKTPTIPTLLGPDGMTSLREYAGYHGGGSGFGGQLRSWNPPSESVDAALLPNFTRGNARADDLVRNNGYAANAIQLHQDHIVGSFFRLSHRPSWRYLGIGEEEARAFSREVEAAWKEFAEDDCCCIDVERKRTFTMMIREGVAMHAFNGELFVQATWDTSSSRLFRTQFRMVSPKRISNPNNTGDSRNCRAGVQINDSGAALGYYVSEDGYPGWMPQKWTWIPRELPGGRASFIHVFEPVEDGQTRGANVFYSVMEQMKMLDTLQNTQLQSAIVKAMYAATIESELDTQSAMDFILGANSQEQRERLTGWIGEIAAYYAAAPVRLGGAKVPHLMPGDSLNLQTAQDTDNGYSVFEQSLLRYIAAGLGVSYEQLSRNYAQMSYSTARASANESWAYFMGRRKFVASRQASQMFLCWLEEAIVRRVVTLPSKARFSFQEARSAWGNCDWIGSGRMAIDGLKEVQEAVMLIEAGLSTYEKECAKRGDDYQEIFAQQVRETMERRAAGLKPPAWAAAAFESGLRQSTEEEKSDSRAA\n",
      "> 4\n",
      "MAFNEPLMLEPAYARVFFCALAGQLGISSLTDAVSGDSLTAQEALATLALSGDDDGPRQARSYQVMNGIAVLPVSGTLVSRTRALQPYSGMTGYNGIIARLQQAASDPMVDGILLDMDTPGGMVAGAFDCADIIARVRDIKPVWALANDMNCSAGQLLASAASRRLVTQTARTGSIGVMMAHSNYGAALEKQGVEITLIYSGSHKVDGNPYSHLPDDVRETLQSRMDATRQMFAQKVSAYTGLSVQVVLDTEAAVYSGQEAIDAGLADELVNSTDAITVMRDALDARKSRLSGGRMTKETQSTTVSATASQADVTDVVPATEGENASAAQPDVNAQITAAVAAENSRIMGILNCEEAHGREEQARVLAETPGMTVKTARRILAAAPQSAQARSDTALDRLMQGAPAPLAAGNPASDAVNDLLNTPV\n"
     ]
    }
   ],
   "source": [
    "!cat sal_seqs.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon doing the BLAST search, I found that the genes are:\n",
    "\n",
    "|Length rank| Description|\n",
    "|:---:|:---:|\n",
    "|1 | histine kinase |\n",
    "|2 | DNA repair protein MutS|\n",
    "|3 | formate hydrogenlyase transcriptional activator|\n",
    "|4 | L-fucose isomerase |\n",
    "|5 | transcriptional regulator HilA (invasion regulator)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.3\n",
      "IPython 7.1.1\n",
      "\n",
      "re 2.2.1\n",
      "numpy 1.16.4\n",
      "jupyterlab 0.35.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p re,numpy,jupyterlab"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
